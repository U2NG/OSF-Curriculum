# Introducing the Problem

## Learning objectives
* Understand the current issues and barriers to reproducibility
* Understand why the whole research workflow is important
* Understand documentation/organizational issues underpinning reproducibility

## What is the problem?

Researchers often have three broad goals for their work. The first is that they are interested in studying innovative ideas; they want to discover new things about the world. Second, they are interested in producing reproducible results; they want to see their results as reliable, and they want others to be able to find them again. Finally, they want to build off their own and others' work and in order to accumulate knowledge over time; they want research to move our understanding of a topic forward. 

Published, peer-reviewed scientific literature is the store of what is "known," it is meant to embody these three ideals.  However, there has been a growing concern that many of the findings in the published literature may not be replicable. There is evidence from a broad range of fields, including cancer biology, psychology, and political science, that the published literature may not be as reliable as we would hope. A few high profile cases of fraud, underline the issue, but they are not representative of the entire issue of reproducibility. This lesson is intended to cast light on seemingly standard research practices that are detrimental to scientific ideals. 


## What is Reproducibility?

Reproducibility is a broad term that has been used by many different people to mean different things, so it is important to clarify what it means in this context. 

One way in which a study can be reproducible is if you took a researcher's data and reran their code/analysis scripts. In this case you would be able to reproduce the same numbers that have been reported in their research paper. This is sometimes called `computational reproducibility` and might sound rather simple, but can be surprisingly tricky to achieve. For example, the Quarterly Journal of Political Science requires that all submitted articles also submit a ‘replication package,’ which includes all the data and code required to replicate the numbers mentioned in the articles. These are then subjected to internal review. Over the last two years, 14 of the 24 empirical papers, or 58 percent, subjected to this review showed differences between the results reported in the paper and the results obtained from the internal review.

Another type of reproducibility is the question of whether, given the available details, the methodology can be mimicked. Do we have enough information to rerun the experiment or survey the way it was originally conducted? This is sometimes referred to as `empirical reproducibility`.

Finally, there is the question of whether we have enough information to completely reproduce the study's protocol, the analyses, and run them on an independent data set. Would we come to the same statistical conclusions as the original study given these new data? This is often referred to as the `replicability` of the study.

All three of these points are important, and you’ll notice that the third type could not even be attempted without the first two. We want the results of studies to be reproducible and findings to replicate. For this workshop, we will be talking about things you can do that help increase all three types of reproducibility with the end goal of making scientific studies more reproducible and findings more replicable.


## What is leading to low levels of reproducibility?

When talking about issues of reproducibility, we aren’t talking about fraud. We are talking about normative practices that act as barriers. If the lack of reproducible research is not caused by fraud, what is leading to the problem? There are a number of contributing factors, but one of the big issues is a lack of documentation and transparency. Here is an abstract representation of the research lifecycle. 

![research lifecycle](intro_figs/research_lifecycle.png)


According to the research lifecycle, the only part of this process that gets shared with people outside your lab is the final step—the published report. Even lab members are likely to forget specifics after several months have passed. As time passes and harddrives and passwords are lost, researchers come to rely on their publications as guides to their own work. Using only the published report to draw conclusions can create several problems. Firstly, published reports are often lacking specific details, so it can be very difficult to determine exactly what was done based solely on the information provided in a journal. Secondly, the published report often doesn’t give us an indication of how the research question, methodology, or analysis strategies may have changed over time. The evolution of these protocols can give important information for evaluating the conclusions of the research. Thus, not documenting and being transparent about the entire research process is problematic. Finally, there is bias against publishing non-statistically significant findings. This leads to a large ‘file drawer’ effect, where many studies don’t get published. If we better document the complete process of all research, not just published studies, more accurate information is given about the breadth of research being conducted. 

## Why should you care about increasing reproducibility?

Low levels of reproducibility and replicability are a problem for a number of reasons. A familiar justification is that if findings of studies don't replicate, this may indicate that our conclusions are incomplete or flawed. This puts the horse before the cart, however: If the supporting documentation to reproduce an experiment is unavailable, that means the conclusions cannot be re-evaluated. Ultimately, poor reproducibility makes it difficult to attempt to validate scientific knowledge.

Low levels of reproducibility also have an impact closer to home. Specifically, it can make the work in your own lab less efficient. Labs are transient; one graduate student starts a project, leaves, and another graduate student tries to pick up or extend upon their project. Perhaps a paper is submitted for review. Six months later the editor asks for new analyses, so you have to search for your data and analyses again. Both scenarios are contingent on knowing where all your research is and being diligent about the transfer and organization of knowledge within your lab—at any point in a project. In general, researchers don't do this well at the moment, therefore our current practices make it hard for us to replicate and build off our own work, often leading to a waste of time and lab resources. 

Learning about and implementing more reproducible practices will help both your own work and science as a whole. 


## What will happen in this workshop?

This workshop introduces ways to improve the documentation and transparency of your workflow. It will introduce tools that can help you implement these changes. An example research study will provide the basis for the workshop, requiring simulated research groups that contain a PI, graduate student, and research assistant. This workshop asks participants to collectively build an open, transparent research project from start to finish in order to learn good project management practices while using the Open Science Framework (OSF). Projects will be shared at the end of the workshop. 

## Group set-up

> Activity: Count off in 3s for group creation

* Count off in 3s, skipping participants without a computer. Ask those participants to look on with a group. 
* Each group of 3 will work together
* 1s are assigned to be PIs, 2s are graduate student collaborators, 3s are research assistants

> Activity: Sign-up or login to [visit OSF](https://osf.io)

*Participants each sign up at osf.io to create an account or sign in.





